digraph {
	graph [size="59.55,59.55"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	140253282367776 [label="
 (1, 10)" fillcolor=darkolivegreen1]
	140253283292816 [label=AddmmBackward0]
	140253283299920 -> 140253283292816
	140253281596848 [label="model.fc.bias
 (10)" fillcolor=lightblue]
	140253281596848 -> 140253283299920
	140253283299920 [label=AccumulateGrad]
	140253283295120 -> 140253283292816
	140253283295120 [label=ViewBackward0]
	140253283290416 -> 140253283295120
	140253283290416 [label=MeanBackward1]
	140253283288112 -> 140253283290416
	140253283288112 [label=ReluBackward0]
	140253283294544 -> 140253283288112
	140253283294544 [label=AddBackward0]
	140253283290272 -> 140253283294544
	140253283290272 [label=NativeBatchNormBackward0]
	140253283289792 -> 140253283290272
	140253283289792 [label=ConvolutionBackward0]
	140253283298384 -> 140253283289792
	140253283298384 [label=ReluBackward0]
	140253283302368 -> 140253283298384
	140253283302368 [label=NativeBatchNormBackward0]
	140253283302224 -> 140253283302368
	140253283302224 [label=ConvolutionBackward0]
	140253283290128 -> 140253283302224
	140253283290128 [label=ReluBackward0]
	140253283294880 -> 140253283290128
	140253283294880 [label=AddBackward0]
	140253283294784 -> 140253283294880
	140253283294784 [label=NativeBatchNormBackward0]
	140253283287296 -> 140253283294784
	140253283287296 [label=ConvolutionBackward0]
	140253283288400 -> 140253283287296
	140253283288400 [label=ReluBackward0]
	140253283288304 -> 140253283288400
	140253283288304 [label=NativeBatchNormBackward0]
	140253283288592 -> 140253283288304
	140253283288592 [label=ConvolutionBackward0]
	140253283293584 -> 140253283288592
	140253283293584 [label=ReluBackward0]
	140253283296272 -> 140253283293584
	140253283296272 [label=AddBackward0]
	140253283301024 -> 140253283296272
	140253283301024 [label=NativeBatchNormBackward0]
	140253283296320 -> 140253283301024
	140253283296320 [label=ConvolutionBackward0]
	140253283292960 -> 140253283296320
	140253283292960 [label=ReluBackward0]
	140253283295792 -> 140253283292960
	140253283295792 [label=NativeBatchNormBackward0]
	140253283295888 -> 140253283295792
	140253283295888 [label=ConvolutionBackward0]
	140253283301072 -> 140253283295888
	140253283301072 [label=ReluBackward0]
	140253283296080 -> 140253283301072
	140253283296080 [label=AddBackward0]
	140253283295984 -> 140253283296080
	140253283295984 [label=NativeBatchNormBackward0]
	140253283292528 -> 140253283295984
	140253283292528 [label=ConvolutionBackward0]
	140253283302944 -> 140253283292528
	140253283302944 [label=ReluBackward0]
	140253283297472 -> 140253283302944
	140253283297472 [label=NativeBatchNormBackward0]
	140253283302656 -> 140253283297472
	140253283302656 [label=ConvolutionBackward0]
	140253283301648 -> 140253283302656
	140253283301648 [label=ReluBackward0]
	140253283290608 -> 140253283301648
	140253283290608 [label=AddBackward0]
	140253283290800 -> 140253283290608
	140253283290800 [label=NativeBatchNormBackward0]
	140253283301840 -> 140253283290800
	140253283301840 [label=ConvolutionBackward0]
	140253283303088 -> 140253283301840
	140253283303088 [label=ReluBackward0]
	140253283290704 -> 140253283303088
	140253283290704 [label=NativeBatchNormBackward0]
	140253283290560 -> 140253283290704
	140253283290560 [label=ConvolutionBackward0]
	140253283288208 -> 140253283290560
	140253283288208 [label=ReluBackward0]
	140253283289648 -> 140253283288208
	140253283289648 [label=AddBackward0]
	140253283289264 -> 140253283289648
	140253283289264 [label=NativeBatchNormBackward0]
	140253283292240 -> 140253283289264
	140253283292240 [label=ConvolutionBackward0]
	140253283299104 -> 140253283292240
	140253283299104 [label=ReluBackward0]
	140253283300880 -> 140253283299104
	140253283300880 [label=NativeBatchNormBackward0]
	140253283300784 -> 140253283300880
	140253283300784 [label=ConvolutionBackward0]
	140253283297520 -> 140253283300784
	140253283297520 [label=ReluBackward0]
	140253283295456 -> 140253283297520
	140253283295456 [label=AddBackward0]
	140253283295408 -> 140253283295456
	140253283295408 [label=NativeBatchNormBackward0]
	140253283293056 -> 140253283295408
	140253283293056 [label=ConvolutionBackward0]
	140253283297904 -> 140253283293056
	140253283297904 [label=ReluBackward0]
	140253283297808 -> 140253283297904
	140253283297808 [label=NativeBatchNormBackward0]
	140253283297760 -> 140253283297808
	140253283297760 [label=ConvolutionBackward0]
	140253283295360 -> 140253283297760
	140253283295360 [label=ReluBackward0]
	140253283296656 -> 140253283295360
	140253283296656 [label=AddBackward0]
	140253283296560 -> 140253283296656
	140253283296560 [label=NativeBatchNormBackward0]
	140253283289840 -> 140253283296560
	140253283289840 [label=ConvolutionBackward0]
	140253283289936 -> 140253283289840
	140253283289936 [label=ReluBackward0]
	140253283038592 -> 140253283289936
	140253283038592 [label=NativeBatchNormBackward0]
	140253283031920 -> 140253283038592
	140253283031920 [label=ConvolutionBackward0]
	140253283296608 -> 140253283031920
	140253283296608 [label=MaxPool2DWithIndicesBackward0]
	140253283040416 -> 140253283296608
	140253283040416 [label=ReluBackward0]
	140253283033216 -> 140253283040416
	140253283033216 [label=NativeBatchNormBackward0]
	140253283039504 -> 140253283033216
	140253283039504 [label=ConvolutionBackward0]
	140253283038832 -> 140253283039504
	140253284248816 [label="model.conv1.weight
 (64, 3, 7, 7)" fillcolor=lightblue]
	140253284248816 -> 140253283038832
	140253283038832 [label=AccumulateGrad]
	140253283040560 -> 140253283033216
	140253479324944 [label="model.bn1.weight
 (64)" fillcolor=lightblue]
	140253479324944 -> 140253283040560
	140253283040560 [label=AccumulateGrad]
	140253283029616 -> 140253283033216
	140253479335184 [label="model.bn1.bias
 (64)" fillcolor=lightblue]
	140253479335184 -> 140253283029616
	140253283029616 [label=AccumulateGrad]
	140253283039024 -> 140253283031920
	140253281595968 [label="model.layer1.0.conv1.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140253281595968 -> 140253283039024
	140253283039024 [label=AccumulateGrad]
	140253283028944 -> 140253283038592
	140253281593888 [label="model.layer1.0.bn1.weight
 (64)" fillcolor=lightblue]
	140253281593888 -> 140253283028944
	140253283028944 [label=AccumulateGrad]
	140253283038352 -> 140253283038592
	140253281595408 [label="model.layer1.0.bn1.bias
 (64)" fillcolor=lightblue]
	140253281595408 -> 140253283038352
	140253283038352 [label=AccumulateGrad]
	140253283035376 -> 140253283289840
	140253281594768 [label="model.layer1.0.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140253281594768 -> 140253283035376
	140253283035376 [label=AccumulateGrad]
	140253283296464 -> 140253283296560
	140253281593248 [label="model.layer1.0.bn2.weight
 (64)" fillcolor=lightblue]
	140253281593248 -> 140253283296464
	140253283296464 [label=AccumulateGrad]
	140253283296512 -> 140253283296560
	140253281595568 [label="model.layer1.0.bn2.bias
 (64)" fillcolor=lightblue]
	140253281595568 -> 140253283296512
	140253283296512 [label=AccumulateGrad]
	140253283296608 -> 140253283296656
	140253283296752 -> 140253283297760
	140253281598368 [label="model.layer1.1.conv1.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140253281598368 -> 140253283296752
	140253283296752 [label=AccumulateGrad]
	140253283297856 -> 140253283297808
	140253281598128 [label="model.layer1.1.bn1.weight
 (64)" fillcolor=lightblue]
	140253281598128 -> 140253283297856
	140253283297856 [label=AccumulateGrad]
	140253283297952 -> 140253283297808
	140253281588208 [label="model.layer1.1.bn1.bias
 (64)" fillcolor=lightblue]
	140253281588208 -> 140253283297952
	140253283297952 [label=AccumulateGrad]
	140253283297568 -> 140253283293056
	140253281590528 [label="model.layer1.1.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140253281590528 -> 140253283297568
	140253283297568 [label=AccumulateGrad]
	140253283293008 -> 140253283295408
	140253281596928 [label="model.layer1.1.bn2.weight
 (64)" fillcolor=lightblue]
	140253281596928 -> 140253283293008
	140253283293008 [label=AccumulateGrad]
	140253283295312 -> 140253283295408
	140253281589808 [label="model.layer1.1.bn2.bias
 (64)" fillcolor=lightblue]
	140253281589808 -> 140253283295312
	140253283295312 [label=AccumulateGrad]
	140253283295360 -> 140253283295456
	140253283300640 -> 140253283300784
	140253281598448 [label="model.layer2.0.conv1.weight
 (128, 64, 3, 3)" fillcolor=lightblue]
	140253281598448 -> 140253283300640
	140253283300640 [label=AccumulateGrad]
	140253283300832 -> 140253283300880
	140253281593488 [label="model.layer2.0.bn1.weight
 (128)" fillcolor=lightblue]
	140253281593488 -> 140253283300832
	140253283300832 [label=AccumulateGrad]
	140253283299152 -> 140253283300880
	140253281594688 [label="model.layer2.0.bn1.bias
 (128)" fillcolor=lightblue]
	140253281594688 -> 140253283299152
	140253283299152 [label=AccumulateGrad]
	140253283301600 -> 140253283292240
	140253281589248 [label="model.layer2.0.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	140253281589248 -> 140253283301600
	140253283301600 [label=AccumulateGrad]
	140253283289360 -> 140253283289264
	140253281589648 [label="model.layer2.0.bn2.weight
 (128)" fillcolor=lightblue]
	140253281589648 -> 140253283289360
	140253283289360 [label=AccumulateGrad]
	140253283289312 -> 140253283289264
	140253281588768 [label="model.layer2.0.bn2.bias
 (128)" fillcolor=lightblue]
	140253281588768 -> 140253283289312
	140253283289312 [label=AccumulateGrad]
	140253283289120 -> 140253283289648
	140253283289120 [label=NativeBatchNormBackward0]
	140253283299248 -> 140253283289120
	140253283299248 [label=ConvolutionBackward0]
	140253283297520 -> 140253283299248
	140253283302848 -> 140253283299248
	140253281596768 [label="model.layer2.0.downsample.0.weight
 (128, 64, 1, 1)" fillcolor=lightblue]
	140253281596768 -> 140253283302848
	140253283302848 [label=AccumulateGrad]
	140253283301168 -> 140253283289120
	140253281594928 [label="model.layer2.0.downsample.1.weight
 (128)" fillcolor=lightblue]
	140253281594928 -> 140253283301168
	140253283301168 [label=AccumulateGrad]
	140253283292432 -> 140253283289120
	140253281593968 [label="model.layer2.0.downsample.1.bias
 (128)" fillcolor=lightblue]
	140253281593968 -> 140253283292432
	140253283292432 [label=AccumulateGrad]
	140253283289456 -> 140253283290560
	140253281589408 [label="model.layer2.1.conv1.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	140253281589408 -> 140253283289456
	140253283289456 [label=AccumulateGrad]
	140253283287824 -> 140253283290704
	140253281589568 [label="model.layer2.1.bn1.weight
 (128)" fillcolor=lightblue]
	140253281589568 -> 140253283287824
	140253283287824 [label=AccumulateGrad]
	140253283287968 -> 140253283290704
	140253281592928 [label="model.layer2.1.bn1.bias
 (128)" fillcolor=lightblue]
	140253281592928 -> 140253283287968
	140253283287968 [label=AccumulateGrad]
	140253283293200 -> 140253283301840
	140253281595648 [label="model.layer2.1.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	140253281595648 -> 140253283293200
	140253283293200 [label=AccumulateGrad]
	140253283290992 -> 140253283290800
	140253281592528 [label="model.layer2.1.bn2.weight
 (128)" fillcolor=lightblue]
	140253281592528 -> 140253283290992
	140253283290992 [label=AccumulateGrad]
	140253283290896 -> 140253283290800
	140253281587808 [label="model.layer2.1.bn2.bias
 (128)" fillcolor=lightblue]
	140253281587808 -> 140253283290896
	140253283290896 [label=AccumulateGrad]
	140253283288208 -> 140253283290608
	140253283301696 -> 140253283302656
	140253281662144 [label="model.layer3.0.conv1.weight
 (256, 128, 3, 3)" fillcolor=lightblue]
	140253281662144 -> 140253283301696
	140253283301696 [label=AccumulateGrad]
	140253283287776 -> 140253283297472
	140253281662304 [label="model.layer3.0.bn1.weight
 (256)" fillcolor=lightblue]
	140253281662304 -> 140253283287776
	140253283287776 [label=AccumulateGrad]
	140253283302992 -> 140253283297472
	140253281662224 [label="model.layer3.0.bn1.bias
 (256)" fillcolor=lightblue]
	140253281662224 -> 140253283302992
	140253283302992 [label=AccumulateGrad]
	140253283302608 -> 140253283292528
	140253281663184 [label="model.layer3.0.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	140253281663184 -> 140253283302608
	140253283302608 [label=AccumulateGrad]
	140253283292336 -> 140253283295984
	140253281663264 [label="model.layer3.0.bn2.weight
 (256)" fillcolor=lightblue]
	140253281663264 -> 140253283292336
	140253283292336 [label=AccumulateGrad]
	140253283295936 -> 140253283295984
	140253281663104 [label="model.layer3.0.bn2.bias
 (256)" fillcolor=lightblue]
	140253281663104 -> 140253283295936
	140253283295936 [label=AccumulateGrad]
	140253283296032 -> 140253283296080
	140253283296032 [label=NativeBatchNormBackward0]
	140253283302800 -> 140253283296032
	140253283302800 [label=ConvolutionBackward0]
	140253283301648 -> 140253283302800
	140253283301792 -> 140253283302800
	140253283206624 [label="model.layer3.0.downsample.0.weight
 (256, 128, 1, 1)" fillcolor=lightblue]
	140253283206624 -> 140253283301792
	140253283301792 [label=AccumulateGrad]
	140253283302560 -> 140253283296032
	140253283217664 [label="model.layer3.0.downsample.1.weight
 (256)" fillcolor=lightblue]
	140253283217664 -> 140253283302560
	140253283302560 [label=AccumulateGrad]
	140253283301744 -> 140253283296032
	140253283218384 [label="model.layer3.0.downsample.1.bias
 (256)" fillcolor=lightblue]
	140253283218384 -> 140253283301744
	140253283301744 [label=AccumulateGrad]
	140253283296944 -> 140253283295888
	140253281663344 [label="model.layer3.1.conv1.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	140253281663344 -> 140253283296944
	140253283296944 [label=AccumulateGrad]
	140253283295840 -> 140253283295792
	140253281663424 [label="model.layer3.1.bn1.weight
 (256)" fillcolor=lightblue]
	140253281663424 -> 140253283295840
	140253283295840 [label=AccumulateGrad]
	140253283295696 -> 140253283295792
	140253281663904 [label="model.layer3.1.bn1.bias
 (256)" fillcolor=lightblue]
	140253281663904 -> 140253283295696
	140253283295696 [label=AccumulateGrad]
	140253283296992 -> 140253283296320
	140253281664464 [label="model.layer3.1.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	140253281664464 -> 140253283296992
	140253283296992 [label=AccumulateGrad]
	140253283301120 -> 140253283301024
	140253281664224 [label="model.layer3.1.bn2.weight
 (256)" fillcolor=lightblue]
	140253281664224 -> 140253283301120
	140253283301120 [label=AccumulateGrad]
	140253283296416 -> 140253283301024
	140253281664144 [label="model.layer3.1.bn2.bias
 (256)" fillcolor=lightblue]
	140253281664144 -> 140253283296416
	140253283296416 [label=AccumulateGrad]
	140253283301072 -> 140253283296272
	140253283293680 -> 140253283288592
	140253281586928 [label="model.layer4.0.conv1.weight
 (512, 256, 3, 3)" fillcolor=lightblue]
	140253281586928 -> 140253283293680
	140253283293680 [label=AccumulateGrad]
	140253283287440 -> 140253283288304
	140253281587248 [label="model.layer4.0.bn1.weight
 (512)" fillcolor=lightblue]
	140253281587248 -> 140253283287440
	140253283287440 [label=AccumulateGrad]
	140253283288544 -> 140253283288304
	140253281587488 [label="model.layer4.0.bn1.bias
 (512)" fillcolor=lightblue]
	140253281587488 -> 140253283288544
	140253283288544 [label=AccumulateGrad]
	140253283287536 -> 140253283287296
	140253281586288 [label="model.layer4.0.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	140253281586288 -> 140253283287536
	140253283287536 [label=AccumulateGrad]
	140253283287344 -> 140253283294784
	140253281583328 [label="model.layer4.0.bn2.weight
 (512)" fillcolor=lightblue]
	140253281583328 -> 140253283287344
	140253283287344 [label=AccumulateGrad]
	140253283287104 -> 140253283294784
	140253281585648 [label="model.layer4.0.bn2.bias
 (512)" fillcolor=lightblue]
	140253281585648 -> 140253283287104
	140253283287104 [label=AccumulateGrad]
	140253283294832 -> 140253283294880
	140253283294832 [label=NativeBatchNormBackward0]
	140253283294112 -> 140253283294832
	140253283294112 [label=ConvolutionBackward0]
	140253283293584 -> 140253283294112
	140253283293488 -> 140253283294112
	140253281657744 [label="model.layer4.0.downsample.0.weight
 (512, 256, 1, 1)" fillcolor=lightblue]
	140253281657744 -> 140253283293488
	140253283293488 [label=AccumulateGrad]
	140253283287248 -> 140253283294832
	140253281662064 [label="model.layer4.0.downsample.1.weight
 (512)" fillcolor=lightblue]
	140253281662064 -> 140253283287248
	140253283287248 [label=AccumulateGrad]
	140253283287152 -> 140253283294832
	140253281656544 [label="model.layer4.0.downsample.1.bias
 (512)" fillcolor=lightblue]
	140253281656544 -> 140253283287152
	140253283287152 [label=AccumulateGrad]
	140253283294736 -> 140253283302224
	140253281583728 [label="model.layer4.1.conv1.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	140253281583728 -> 140253283294736
	140253283294736 [label=AccumulateGrad]
	140253283302272 -> 140253283302368
	140253281585008 [label="model.layer4.1.bn1.weight
 (512)" fillcolor=lightblue]
	140253281585008 -> 140253283302272
	140253283302272 [label=AccumulateGrad]
	140253283298336 -> 140253283302368
	140253281583408 [label="model.layer4.1.bn1.bias
 (512)" fillcolor=lightblue]
	140253281583408 -> 140253283298336
	140253283298336 [label=AccumulateGrad]
	140253283297328 -> 140253283289792
	140253281584528 [label="model.layer4.1.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	140253281584528 -> 140253283297328
	140253283297328 [label=AccumulateGrad]
	140253283293872 -> 140253283290272
	140253281584848 [label="model.layer4.1.bn2.weight
 (512)" fillcolor=lightblue]
	140253281584848 -> 140253283293872
	140253283293872 [label=AccumulateGrad]
	140253283294160 -> 140253283290272
	140253281584928 [label="model.layer4.1.bn2.bias
 (512)" fillcolor=lightblue]
	140253281584928 -> 140253283294160
	140253283294160 [label=AccumulateGrad]
	140253283290128 -> 140253283294544
	140253283289072 -> 140253283292816
	140253283289072 [label=TBackward0]
	140253283293776 -> 140253283289072
	140253281594128 [label="model.fc.weight
 (10, 512)" fillcolor=lightblue]
	140253281594128 -> 140253283293776
	140253283293776 [label=AccumulateGrad]
	140253283292816 -> 140253282367776
}
